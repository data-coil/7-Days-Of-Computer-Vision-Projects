{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Based Writing Method\n",
    "## Introduction\n",
    "Hello surfer, welcome to this blog where I will be writing a Python code to write something in canvas by moving fingers in front of the camera. Nearly a year ago, I was doing this project but I thougt if I could use just contours then why use gestures? In that project, I used concept of background subtraction and then with the help of contour extraction, I wrote something on canvas. It was 6 part series of blogs and I hope you will find it interesting but I am going to do the same task except using the gestures except of contours and I am not planning on using VUI (Virtual User Interface) here too because if I can use gestures then why bother writng complex code?\n",
    "\n",
    "* [Gesture Based Visually Writing System Using OpenCV and Python](https://q-viper.github.io/2020/08/01/gesture-based-visually-writing-system-using-opencv-and-python/)\n",
    "* [Gesture Based Visually Writing System: Adding Visual User Interface](https://q-viper.github.io/2020/08/11/gesture-based-visually-writing-system-make-a-visual-user-interface/)\n",
    "* [Gesture Based Visually Writing System: Adding Virtual Animationn, New Mode and New VUI](https://q-viper.github.io/2020/08/14/gesture-based-visually-writing-system-adding-virtual-animation-new-mode-and-new-vui/)\n",
    "* [Gesture Based Visually Writing System: Add Slider, More Colors and Optimized OOP code](https://q-viper.github.io/2020/08/21/gesture-based-visually-writing-system-add-slider-more-colors-and-optimized-code/)\n",
    "* [Gesture Based Visually Writing System: Building a Web App Using Flask](https://q-viper.github.io/2020/08/28/gesture-based-visually-writing-system-web-app/)\n",
    "\n",
    "And here is the demo of that system:\n",
    "\n",
    "<figure>\n",
    "<video src = \"https://q-viper.github.io/assets/contour-writing/web app.mp4\" width=\"100%\" controls autoplay loop> </video>\n",
    "<figcaption style = \"text-align:left; font-style:italic\">Gesture writing on Web App</figcaption>\n",
    "</figure> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What will be the difference?\n",
    "Everything will eb different in this project but the end goal is somewhat similar. I will use concept of gestures from earlier projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Actions\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions\n",
    "We will need to map our finger landmarks from pixel world to the new canvas world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show(img, fsize=(10, 10)):\n",
    "    figure = plt.figure(figsize=fsize)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "show(np.zeros((10, 10)))\n",
    "\n",
    "def frame_pos2screen_pos(frame_size=(480, 640), screen_size=(768, 1366), frame_pos=None):\n",
    "    \n",
    "    x,y = screen_size[0]/frame_size[0], screen_size[1]/frame_size[1]\n",
    "    \n",
    "    screen_pos = [frame_pos[0]*y, frame_pos[1]*x]\n",
    "    \n",
    "    return np.array(screen_pos).astype(np.uint32)\n",
    "\n",
    "def euclidean(pt1, pt2):\n",
    "    d = np.sqrt((pt1[0]-pt2[0])**2+(pt1[1]-pt2[1])**2)\n",
    "    return d\n",
    "euclidean((4, 3), (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesture Writing Code Explained\n",
    "\n",
    "* Define the video source and in our case, webcam.\n",
    "```python\n",
    "cam = cv2.VideoCapture(0)\n",
    "```\n",
    "* Define variables `fsize` as frame simze and `ssize` as screen size.\n",
    "```python\n",
    "fsize = (520, 720)\n",
    "ssize = (520, 720)\n",
    "```\n",
    "* Define a background color.\n",
    "```python\n",
    "bg_color = (100, 100, 100)\n",
    "```\n",
    "* Define a pen size and ink size, pen will be a simple cursor like circle and ink will be a actual circle or written pixel.\n",
    "```python\n",
    "pen_size = 8\n",
    "ink_size = 10\n",
    "```\n",
    "* Define colors in a dictionary format as {color_name: color_value}.\n",
    "```python\n",
    "colors = {\"red\": [0, 0, 255], \"blue\":[255, 0, 0], \"green\":[0, 255, 0]}\n",
    "```\n",
    "* Define modes, write, move and erase. \n",
    "```python\n",
    "modes = [\"write\", \"move\", \"erase\"]\n",
    "```\n",
    "* Define variables for storing current mode, last_mode and current_color.\n",
    "```python\n",
    "current_mode = \"draw\"\n",
    "last_mode = None\n",
    "current_color = \"red\"\n",
    "```\n",
    "* Define some rules to take pen color, currently pen color will be color next to the draw color.\n",
    "```python\n",
    "cnames = list(colors.keys())\n",
    "ink_color = colors[current_color]\n",
    "pen_color = np.array(ink_color)-[100, 50, 100]\n",
    "pen_color = pen_color.astype(np.uint8).tolist()\n",
    "```\n",
    "* Define hand and drawing module of mediapipe.\n",
    "```python\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "```\n",
    "* Define variables for ROI rectangle.\n",
    "```python\n",
    "left, top, right, bottom = (400, 100, 700, 300)\n",
    "```\n",
    "* Define a canvas of blank image and then add background color.\n",
    "```python\n",
    "canvas = np.zeros((ssize[0], ssize[1], 3))+bg_color\n",
    "canvas = canvas.astype(np.uint8)\n",
    "```\n",
    "* Define variables for checking every n frames and initialize check count.\n",
    "```python\n",
    "check_every = 5\n",
    "check_cnt = 0\n",
    "```\n",
    "* Define hands module. Use maximum number of hands as 1.\n",
    "```python\n",
    "with mp_hands.Hands(static_image_mode=True,\n",
    "                   max_num_hands = 1,\n",
    "                   min_detection_confidence=0.2) as hands:\n",
    "```\n",
    "* While camera is opened perform operations like read frame.\n",
    "```python\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "```\n",
    "* Add some Gaussian Blur.\n",
    "```python\n",
    "        frame = cv2.GaussianBlur(frame, (5, 5), -1)\n",
    "```\n",
    "* Define a temporary canvas for drawing and pointer. A `temp_canvas` is a canvas that we define in every frame and add new changes into it. Similarly, we will use `pen_canvas` just to view pointer. Both should be of `uint8`.\n",
    "```python\n",
    "        temp_canvas = np.zeros((ssize[0], ssize[1], 3)).astype(np.uint8)\n",
    "        pen_canvas = np.zeros((ssize[0], ssize[1], 3)).astype(np.uint8)\n",
    "```\n",
    "* Flip the frame to look like selfie frame and resize it to given size. Also take height and width of frame. We will use it later to convert landmark positions to frame world.\n",
    "```python           \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.resize(frame, (fsize[1], fsize[0]))\n",
    "        \n",
    "        h, w, _ = frame.shape\n",
    "```\n",
    "* Convert image to RGB and process it to get a result.\n",
    "```python\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = hands.process(rgb)\n",
    "```\n",
    "* Check if hand landmarks has been found and if did, loop through each hand.\n",
    "```python\n",
    "        if res.multi_hand_landmarks:\n",
    "            for hand_landmarks in res.multi_hand_landmarks:\n",
    "```\n",
    "* Take landmarks like:- index tip, thumb tip, middle finger tip etc from hand landmarks and convert it into our frame world.\n",
    "```python\n",
    "                index_tip = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x,\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y,\n",
    "                    w, h)\n",
    "                \n",
    "                index_pip = np.array(mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].x, \n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y, \n",
    "                    w, h))\n",
    "                \n",
    "                thumb_tip = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x, \n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y, \n",
    "                    w, h)\n",
    "                \n",
    "                middle_tip = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x, \n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y, \n",
    "                    w, h)            \n",
    "```\n",
    "* Convert index tip into canvas world. We will first make the list of index tip because we dont want to mess up with original values. Then we will clip the index tip value within the ROI rectangle. Then we will convert that clipped value to current frame world. Finally, we will convert those frame world landmarks to screen world.\n",
    "```python\n",
    "                index_tipm = list(index_tip) # make list\n",
    "                index_tipm[0] = np.clip(index_tipm[0], left, right) # clip cloumn value within left to right\n",
    "                index_tipm[1] = np.clip(index_tipm[1], top, bottom) # clip row value within top to bottom\n",
    "                \n",
    "                index_tipm[0] = (index_tipm[0]-left) * fsize[1]/(right-left) # column value from ROI to frame world\n",
    "                index_tipm[1] = (index_tipm[1]-top) * fsize[0]/(bottom-top) # row value from ROI to frame world\n",
    "                \n",
    "                # convert coordinate from frame world to canvas or screen world\n",
    "                screen_pos = frame_pos2screen_pos(fsize, ssize, index_tipm) \n",
    "```\n",
    "* If check count is equal to check every.\n",
    "```python\n",
    "                if check_cnt >= check_every:\n",
    "```\n",
    "* If thumb tip and index pip is not none then check for distance between these points. If it is below 60 then check for current mode. If current mode is draw or erase then make it move else if current mode is move then make it draw. We want to simulate draw and move mode by single gesture. Something like our smartphone's power button's task to turn on/off display light.\n",
    "```python\n",
    "                    if thumb_tip is not None and index_pip is not None:\n",
    "                        if euclidean(thumb_tip, index_pip)<60:\n",
    "                            if current_mode == \"draw\" or current_mode == \"erase\":\n",
    "                                current_mode = \"move\"\n",
    "                                last_mode = \"draw\"\n",
    "                            elif current_mode == \"move\":\n",
    "                                current_mode=\"draw\"\n",
    "                                last_mode = \"move\"\n",
    "```\n",
    "* If middle tip and index tip is not none then check for distance between these points. If it is below 60 then check for current mode. If current mode is not erase then make it erase else make it move. We want to simulate erase and move mode by single gesture. Something like our smartphone's power button's task to turn on/off display light.\n",
    "```python\n",
    "                    if middle_tip is not None and index_tip is not None:\n",
    "                        if euclidean(index_tip, middle_tip)<60:\n",
    "                            if current_mode != \"erase\":\n",
    "                                current_mode = \"erase\"\n",
    "                            else:\n",
    "                                current_mode = \"move\"\n",
    "                                last_mode = \"erase\"\n",
    "```\n",
    "* If thumb tip and middle tip is not none then check for distance between these points. If it is below 60 then change the current ink color and pen color. The color will be changed in circular basis i.e clockwise.\n",
    "```python\n",
    "                    if thumb_tip is not None and middle_tip is not None:\n",
    "                        if euclidean(thumb_tip, middle_tip)<60:\n",
    "                            current_color = cnames[(cnames.index(current_color)+1)%len(cnames)]\n",
    "                            ink_color = colors[current_color]\n",
    "                            pen_color = np.array(ink_color)-[100, 50, 100]\n",
    "                            pen_color = pen_color.astype(np.uint8).tolist()\n",
    "                            # print(pen_color)\n",
    "```\n",
    "* Change check count to 0.\n",
    "```python\n",
    "                    check_cnt = 0\n",
    "```\n",
    "* Now perform the writing operation. If current mode is draw/erase then we will make a circle in temporary canvas on the screen position that we got after conversion of index tip. The radius will be of ink size. The color will be ink color while draw mode and background color in erase mode. At last, draw a cursor on a pen canvas with pen's size and color.\n",
    "```python                \n",
    "                if current_mode==\"draw\":\n",
    "                    cv2.circle(temp_canvas, screen_pos, int(ink_size), ink_color, -1)\n",
    "                if current_mode==\"erase\":\n",
    "                    cv2.circle(temp_canvas, screen_pos, int(ink_size), bg_color, -1)\n",
    "                cv2.circle(pen_canvas, screen_pos, int(pen_size), pen_color, -1)\n",
    "                \n",
    "```\n",
    "* Draw hand landmarks.\n",
    "```python\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "```\n",
    "* Prepare mask. If current mode is draw or erase, then find mask from temp canvas. Sum the 3 channels of temp canvas and as it was originally zeros array and if something is drawn then that position will be different. Which means its sum will not be 0 and in those positions of canvas where temp canvas is not zero, we will replace values from temp canvas on exact same place.\n",
    "```python\n",
    "        if current_mode in [\"draw\", \"erase\"]:\n",
    "            mask = np.sum(temp_canvas, axis=-1)!=0\n",
    "            canvas[mask]=temp_canvas[mask]\n",
    "```\n",
    "* Make new canvas which will be shown. We don't want to show pen as a static circle but a dynamic and it should be seen moving too. So we will draw pen on the new canvas because old canvas will contain only drawings. Use the same concept of masking as above to draw pen on canvas.\n",
    "```python\n",
    "        ncanvas = canvas.copy()\n",
    "        mask = np.sum(pen_canvas, axis=-1)!=0\n",
    "        ncanvas[mask]=pen_canvas[mask]\n",
    "```\n",
    "* Make an empty image which we will use as an information panel on the top. In this image, we will write information like current mode, color, pen size etc. Then stack this image vertically on our new canvas. We will also resize frame at this point to stack it horizontally with canvas and just to show them stacked in same frame. But make sure to make it in `uint8`type.\n",
    "```python\n",
    "        d = np.zeros((100, ssize[1], 3), dtype=\"int\")\n",
    "        \n",
    "        text = f\"Mode: {current_mode} | Color: {current_color} | Pen: {ink_size}\"\n",
    "\n",
    "        cv2.putText(d, text, (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (200, 100, 200), 2)\n",
    "        \n",
    "        ncanvas = np.vstack([d, ncanvas]).astype(np.uint8)\n",
    "        nshape = ncanvas.shape\n",
    "        \n",
    "        # draw a ROI rectangle\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 1)\n",
    "        \n",
    "        frame = cv2.resize(frame, (nshape[1], nshape[0]))\n",
    "        \n",
    "        cv2.imshow(\"Window\", temp_canvas)\n",
    "        cv2.imshow(\"Canvas\", np.hstack([frame, ncanvas]).astype(np.uint8))\n",
    "```\n",
    "* Increase the count. Wait for the key event to break the loop. And at last, release camera and destroy windows.\n",
    "```python\n",
    "        check_cnt += 1\n",
    "        if cv2.waitKey(1)&0xFF == 27:\n",
    "            break\n",
    "cam.release()\n",
    "#out.release()\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "fsize = (520, 720)\n",
    "ssize = (520, 720)\n",
    "\n",
    "bg_color = (100, 100, 100)\n",
    "\n",
    "pen_size = 15\n",
    "ink_size = 13\n",
    "\n",
    "colors = {\"red\": [0, 0, 255], \"blue\":[255, 0, 0], \"green\":[0, 255, 0]}\n",
    "modes = [\"write\", \"move\", \"erase\"]\n",
    "current_mode = \"draw\"\n",
    "last_mode = None\n",
    "current_color = \"red\"\n",
    "cnames = list(colors.keys())\n",
    "ink_color = colors[current_color]\n",
    "pen_color = np.array(ink_color)-[100, 50, 100]\n",
    "pen_color = pen_color.astype(np.uint8).tolist()\n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "left, top, right, bottom = (400, 100, 700, 300)\n",
    "\n",
    "canvas = np.zeros((ssize[0], ssize[1], 3))+bg_color\n",
    "canvas = canvas.astype(np.uint8)\n",
    "\n",
    "check_every = 5\n",
    "check_cnt = 0\n",
    "\n",
    "#out = cv2.VideoWriter(\"out.avi\", cv2.VideoWriter_fourcc(*'XVID'), 30, (fsize[1], fsize[0]))\n",
    "\n",
    "with mp_hands.Hands(static_image_mode=True,\n",
    "                   max_num_hands = 1,\n",
    "                   min_detection_confidence=0.2) as hands:\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        frame = cv2.GaussianBlur(frame, (5, 5), -1)\n",
    "        temp_canvas = np.zeros((ssize[0], ssize[1], 3)).astype(np.uint8)\n",
    "        pen_canvas = np.zeros((ssize[0], ssize[1], 3)).astype(np.uint8)\n",
    "        \n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.resize(frame, (fsize[1], fsize[0]))\n",
    "        \n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        \n",
    "        \n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = hands.process(rgb)\n",
    "        \n",
    "        if res.multi_hand_landmarks:\n",
    "            for hand_landmarks in res.multi_hand_landmarks:\n",
    "                index_tip = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x,\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y,\n",
    "                    w, h)\n",
    "                \n",
    "                index_pip = np.array(mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].x, \n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y, \n",
    "                    w, h))\n",
    "                \n",
    "                thumb_tip = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x, \n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y, \n",
    "                    w, h)\n",
    "                \n",
    "                middle_tip = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x, \n",
    "                    hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y, \n",
    "                    w, h)\n",
    "            \n",
    "\n",
    "                \n",
    "                #print(index_tip)\n",
    "                index_tipm = list(index_tip)\n",
    "                index_tipm[0] = np.clip(index_tipm[0], left, right)\n",
    "                index_tipm[1] = np.clip(index_tipm[1], top, bottom)\n",
    "                \n",
    "                index_tipm[0] = (index_tipm[0]-left) * fsize[1]/(right-left)\n",
    "                index_tipm[1] = (index_tipm[1]-top) * fsize[0]/(bottom-top)\n",
    "                \n",
    "                #print(index_tipm)\n",
    "                screen_pos = frame_pos2screen_pos(fsize, ssize, index_tipm)\n",
    "                \n",
    "                if check_cnt >= check_every:\n",
    "                    \n",
    "                    if thumb_tip is not None and index_pip is not None:\n",
    "                        if euclidean(thumb_tip, index_pip)<60:\n",
    "                            if current_mode == \"draw\" or current_mode == \"erase\":\n",
    "                                current_mode = \"move\"\n",
    "                                last_mode = \"draw\"\n",
    "                            elif current_mode == \"move\":\n",
    "                                current_mode=\"draw\"\n",
    "                                last_mode = \"move\"\n",
    "                    if middle_tip is not None and index_pip is not None:\n",
    "                        if euclidean(index_tip, middle_tip)<60:\n",
    "                            if current_mode != \"erase\":\n",
    "                                current_mode = \"erase\"\n",
    "                            else:\n",
    "                                current_mode = \"move\"\n",
    "                                last_mode = \"erase\"\n",
    "                    if thumb_tip is not None and middle_tip is not None:\n",
    "                        if euclidean(thumb_tip, middle_tip)<60:\n",
    "                            current_color = cnames[(cnames.index(current_color)+1)%len(cnames)]\n",
    "                            ink_color = colors[current_color]\n",
    "                            pen_color = np.array(ink_color)-[100, 50, 100]\n",
    "                            pen_color = pen_color.astype(np.uint8).tolist()\n",
    "                            # print(pen_color)\n",
    "                            \n",
    "                    check_cnt = 0\n",
    "                \n",
    "                \n",
    "                if current_mode==\"draw\":\n",
    "                    cv2.circle(temp_canvas, screen_pos, int(ink_size), ink_color, -1)\n",
    "                if current_mode==\"erase\":\n",
    "                    cv2.circle(temp_canvas, screen_pos, int(ink_size), bg_color, -1)\n",
    "                cv2.circle(pen_canvas, screen_pos, int(pen_size), pen_color, -1)\n",
    "                \n",
    "                \n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "        if current_mode in [\"draw\", \"erase\"]:\n",
    "            mask = np.sum(temp_canvas, axis=-1)!=0\n",
    "            canvas[mask]=temp_canvas[mask]\n",
    "            \n",
    "        ncanvas = canvas.copy()\n",
    "        mask = np.sum(pen_canvas, axis=-1)!=0\n",
    "        ncanvas[mask]=pen_canvas[mask]\n",
    "        \n",
    "        d = np.zeros((100, ssize[1], 3), dtype=\"int\")\n",
    "        \n",
    "        text = f\"Mode: {current_mode} | Color: {current_color} | Pen: {ink_size}\"\n",
    "\n",
    "        cv2.putText(d, text, (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (200, 100, 200), 2)\n",
    "        \n",
    "        ncanvas = np.vstack([d, ncanvas]).astype(np.uint8)\n",
    "        nshape = ncanvas.shape\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 1)\n",
    "        frame = cv2.resize(frame, (nshape[1], nshape[0]))\n",
    "        \n",
    "        \n",
    "        check_cnt += 1\n",
    "        cv2.imshow(\"Window\", temp_canvas)\n",
    "        cv2.imshow(\"Canvas\", np.hstack([frame, ncanvas]).astype(np.uint8))\n",
    "        if cv2.waitKey(1)&0xFF == 27:\n",
    "            break\n",
    "cam.release()\n",
    "#out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally\n",
    "This was just a demo of what can we do by moving just fingers in front of the camera. I have already done more advanced tasks by contours previously and my next goal will be to add features like sliding cursor size, changing background colors etc. But in the mean time please keep notified on our YouTube for more contents related to this.\n",
    "* [YouTube]()\n",
    "* [GitHub]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_canvas = np.zeros((100, 100, 3))\n",
    "show(cv2.circle(temp_canvas, (50,30), int(5), [100,100,100], 5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
